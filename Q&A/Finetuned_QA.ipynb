{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer\n",
    "from transformers import BertForQuestionAnswering\n",
    "\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-large-uncased-whole-word-masking-finetuned-squad were not used when initializing BertForQuestionAnswering: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "# Initialize tokenizer for corpus of bert-large-uncased\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-large-uncased-whole-word-masking-finetuned-squad')\n",
    "\n",
    "# Initialize model BertForQuestionAnswering for bert-large-uncased\n",
    "model = BertForQuestionAnswering.from_pretrained('bert-large-uncased-whole-word-masking-finetuned-squad')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def answer_question(question, answer_text):\n",
    "    '''\n",
    "    Lấy input là chuỗi string của câu question và answer_text chứa nội dung câu trả lời của câu question.\n",
    "    Xác định từ trong answer_text là câu trả lời và in ra.\n",
    "    '''\n",
    "    # ======== Tokenize ========\n",
    "    # Áp dụng tokenizer cho cặp câu <question, answer_text>. input_ids là concatenate indice của cả 2 câu sau khi đã thêm các token CLS và SEP như mô tả trong tác vụ Question and Answering.\n",
    "    input_ids = tokenizer.encode(question, answer_text)\n",
    "\n",
    "    # ======== Set Segment IDs ========\n",
    "    # Xác định vị trí đầu tiên chứa token [SEP] trong câu.\n",
    "    sep_index = input_ids.index(tokenizer.sep_token_id)\n",
    "\n",
    "    # Tạo segment index đánh dấu các vị trí từ thuộc question (giá trị 0) và answer_text (giá trị 1)\n",
    "    num_seg_a = sep_index + 1\n",
    "    num_seg_b = len(input_ids) - num_seg_a\n",
    "    segment_ids = [0]*num_seg_a + [1]*num_seg_b\n",
    "\n",
    "    # Kiểm tra độ dài segment_ids phải bằng input_ids\n",
    "    assert len(segment_ids) == len(input_ids)\n",
    "    \n",
    "    input_ids = torch.tensor([input_ids])\n",
    "    segment_ids = torch.tensor([segment_ids])\n",
    "\n",
    "    # ======== Evaluate ========\n",
    "    # Dự báo phân phối xác suất của vị trí của từ start và từ end trong chuỗi concatenate <question, answer_text> mà chứa kết quả cho câu trả lời.\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids, token_type_ids=segment_ids)\n",
    "        start_scores, end_scores = outputs.start_logits, outputs.end_logits\n",
    "\n",
    "    # ======== Reconstruct Answer ========\n",
    "    # Tìm ra vị trí start, end với score là cao nhất\n",
    "    answer_start = torch.argmax(start_scores, dim=1).item()\n",
    "    answer_end = torch.argmax(end_scores, dim=1).item()\n",
    "\n",
    "    # Chuyển ngược từ input_ids sang list tokens\n",
    "    tokens = tokenizer.convert_ids_to_tokens(input_ids[0])\n",
    "    print(tokens)\n",
    "\n",
    "    # Token đầu tiên của câu trả lời\n",
    "    answer = tokens[answer_start]\n",
    "\n",
    "    # Lựa chọn các thành phần còn lại của câu trả lời và join chúng với whitespace.\n",
    "    for i in range(answer_start + 1, answer_end + 1):\n",
    "        \n",
    "        # Nếu token là một subword token (có dấu ## ở đầu) thì combine vào answer bằng token gốc (loại bỏ dấu ##).\n",
    "        if tokens[i].startswith('##'):\n",
    "            answer += tokens[i][2:]\n",
    "        \n",
    "        # Nếu trái lại thì combine trực tiếp vào answer.\n",
    "        else:\n",
    "            answer += ' ' + tokens[i]\n",
    "            \n",
    "    print('Question: \"' + question + '\"')\n",
    "    print('Answer: \"' + answer + '\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[CLS]', 'what', 'is', 'my', 'dog', 'name', '?', '[SEP]', 'i', 'have', 'a', 'dog', '.', 'it', \"'\", 's', 'name', 'is', 'ricky', '.', 'i', 'get', 'it', 'at', 'my', '15th', 'birthday', ',', 'when', 'it', 'was', 'a', 'puppy', '.', '[SEP]']\n",
      "Question: \"what is my dog name?\"\n",
      "Answer: \"ricky\"\n"
     ]
    }
   ],
   "source": [
    "question = \"what is my dog name?\"\n",
    "paragraph = \"I have a dog. It's name is Ricky. I get it at my 15th birthday, when it was a puppy.\"\n",
    "\n",
    "answer_question(question, paragraph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[CLS]', 'what', 'is', 'the', 'capital', 'of', 'france', '?', '[SEP]', 'the', 'capital', 'of', 'france', 'is', 'paris', '.', '[SEP]']\n",
      "Question: \"What is the capital of France?\"\n",
      "Answer: \"paris\"\n"
     ]
    }
   ],
   "source": [
    "question = \"What is the capital of France?\"\n",
    "answer_text = \"The capital of France is Paris.\"\n",
    "answer_question(question, answer_text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
